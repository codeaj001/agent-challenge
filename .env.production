# Production Environment Configuration for GitHub Reporter
# ================================================================

# Production AI Model Configuration
# Choose your production AI endpoint:

# Option 1: Nosana Production Endpoint (Recommended for production)
API_BASE_URL=https://nos-dep-2.node.k8s.prd.nos.ci/qwen-3-8b-skea/api
MODEL_NAME_AT_ENDPOINT=qwen3:8b

# Option 2: Custom Production Ollama Instance
# API_BASE_URL=https://your-ollama-server.com/api
# MODEL_NAME_AT_ENDPOINT=qwen2.5:32b

# Option 3: Local Development (NOT for production)
# API_BASE_URL=http://127.0.0.1:11434/api
# MODEL_NAME_AT_ENDPOINT=qwen2.5:1.5b

# GitHub API Configuration
# CRITICAL: Set this for production to avoid rate limiting
# Generate at: https://github.com/settings/tokens
# Permissions needed: public_repo, read:org, read:user
# GITHUB_TOKEN=your_github_token_here

# Application Configuration
NODE_ENV=production
PORT=8080
HOST=0.0.0.0

# Database Configuration
# For production, consider using a persistent volume
DATABASE_URL=file:./data/github-reporter.db

# Logging Configuration
LOG_LEVEL=info
LOG_FORMAT=json

# Security Configuration
# Add your allowed origins for CORS
CORS_ORIGINS=*

# Health Check Configuration
HEALTH_CHECK_INTERVAL=30000
HEALTH_CHECK_TIMEOUT=5000

# Memory Configuration
MEMORY_CLEANUP_INTERVAL=3600000  # 1 hour in milliseconds
MAX_MEMORY_ENTRIES=10000

# Performance Configuration
MAX_CONCURRENT_REQUESTS=10
REQUEST_TIMEOUT=30000  # 30 seconds

# Monitoring Configuration (Optional)
# MONITORING_ENABLED=true
# METRICS_PORT=9090
